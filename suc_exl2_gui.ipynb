{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYjiNb-Pdx4S"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/turboderp/exui\n",
        "!cd exui && pip install -r requirements.txt\n",
        "!git clone https://github.com/turboderp/exllamav2\n",
        "!cd exllamav2 && python setup.py install --user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0dzbB8zkx-Q",
        "outputId": "ba1aae5e-4b2e-4fc3-a455-720ae00d4d39"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'exui'...\n",
            "remote: Enumerating objects: 714, done.\u001b[K\n",
            "remote: Counting objects: 100% (229/229), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 714 (delta 176), reused 171 (delta 150), pack-reused 485 (from 3)\u001b[K\n",
            "Receiving objects: 100% (714/714), 2.90 MiB | 18.92 MiB/s, done.\n",
            "Resolving deltas: 100% (422/422), done.\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (12.0.0)\n",
            "Collecting exllamav2>=0.2.3 (from -r requirements.txt (line 3))\n",
            "  Downloading exllamav2-0.2.8-py3-none-any.whl.metadata (467 bytes)\n",
            "Requirement already satisfied: Flask>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (3.1.0)\n",
            "Collecting waitress>=2.1.2 (from -r requirements.txt (line 5))\n",
            "  Downloading waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: nvidia-ml-py<13.0.0a0,>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from pynvml->-r requirements.txt (line 2)) (12.570.86)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from exllamav2>=0.2.3->-r requirements.txt (line 3)) (2.2.2)\n",
            "Collecting ninja (from exllamav2>=0.2.3->-r requirements.txt (line 3))\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting fastparquet (from exllamav2>=0.2.3->-r requirements.txt (line 3))\n",
            "  Downloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from exllamav2>=0.2.3->-r requirements.txt (line 3)) (0.5.3)\n",
            "Requirement already satisfied: sentencepiece>=0.1.97 in /usr/local/lib/python3.11/dist-packages (from exllamav2>=0.2.3->-r requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from exllamav2>=0.2.3->-r requirements.txt (line 3)) (2.18.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from exllamav2>=0.2.3->-r requirements.txt (line 3)) (15.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from exllamav2>=0.2.3->-r requirements.txt (line 3)) (2024.11.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from exllamav2>=0.2.3->-r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from exllamav2>=0.2.3->-r requirements.txt (line 3)) (13.9.4)\n",
            "Requirement already satisfied: pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from exllamav2>=0.2.3->-r requirements.txt (line 3)) (11.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=2.3.2->-r requirements.txt (line 4)) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=2.3.2->-r requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=2.3.2->-r requirements.txt (line 4)) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=2.3.2->-r requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.11/dist-packages (from fastparquet->exllamav2>=0.2.3->-r requirements.txt (line 3)) (2.9.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastparquet->exllamav2>=0.2.3->-r requirements.txt (line 3)) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->exllamav2>=0.2.3->-r requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->exllamav2>=0.2.3->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->exllamav2>=0.2.3->-r requirements.txt (line 3)) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->exllamav2>=0.2.3->-r requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->exllamav2>=0.2.3->-r requirements.txt (line 3)) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->exllamav2>=0.2.3->-r requirements.txt (line 3)) (1.17.0)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exllamav2-0.2.8-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading waitress-3.0.2-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastparquet-2024.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: waitress, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, fastparquet, exllamav2\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed exllamav2-0.2.8 fastparquet-2024.11.0 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 waitress-3.0.2\n",
            "Cloning into 'exllamav2'...\n",
            "remote: Enumerating objects: 8145, done.\u001b[K\n",
            "remote: Counting objects: 100% (3398/3398), done.\u001b[K\n",
            "remote: Compressing objects: 100% (972/972), done.\u001b[K\n",
            "remote: Total 8145 (delta 2497), reused 2454 (delta 2426), pack-reused 4747 (from 2)\u001b[K\n",
            "Receiving objects: 100% (8145/8145), 21.93 MiB | 33.27 MiB/s, done.\n",
            "Resolving deltas: 100% (5869/5869), done.\n",
            "Version: 0.2.8\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
            "warning: no previously-included files matching 'dni_*' found anywhere in distribution\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.conversion' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.conversion' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.conversion' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.conversion' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.conversion' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.conversion.standard_cal_data' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.conversion.standard_cal_data' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.conversion.standard_cal_data' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.conversion.standard_cal_data' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.conversion.standard_cal_data' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.exllamav2_ext' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.exllamav2_ext' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.exllamav2_ext' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.exllamav2_ext' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.exllamav2_ext' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.exllamav2_ext.cpp' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.exllamav2_ext.cpp' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.exllamav2_ext.cpp' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.exllamav2_ext.cpp' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.exllamav2_ext.cpp' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.exllamav2_ext.cuda' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.exllamav2_ext.cuda' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.exllamav2_ext.cuda' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.exllamav2_ext.cuda' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.exllamav2_ext.cuda' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.exllamav2_ext.cuda.comp_units' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.exllamav2_ext.cuda.comp_units' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.exllamav2_ext.cuda.comp_units' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.exllamav2_ext.cuda.comp_units' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.exllamav2_ext.cuda.comp_units' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.exllamav2_ext.cuda.quant' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.exllamav2_ext.cuda.quant' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.exllamav2_ext.cuda.quant' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.exllamav2_ext.cuda.quant' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.exllamav2_ext.cuda.quant' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.experimental' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.experimental' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.experimental' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.experimental' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.experimental' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.generator.filters' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.generator.filters' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.generator.filters' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.generator.filters' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.generator.filters' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.hadamard' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.hadamard' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.hadamard' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.hadamard' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.hadamard' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.server' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.server' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.server' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.server' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.server' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.tokenizer' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.tokenizer' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.tokenizer' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.tokenizer' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.tokenizer' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.vlm' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.vlm' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.vlm' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.vlm' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.vlm' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/setuptools/command/build_py.py:218: _Warning: Package 'exllamav2.vlm.processor' is absent from the `packages` configuration.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        ############################\n",
            "        # Package would be ignored #\n",
            "        ############################\n",
            "        Python recognizes 'exllamav2.vlm.processor' as an importable package[^1],\n",
            "        but it is absent from setuptools' `packages` configuration.\n",
            "\n",
            "        This leads to an ambiguous overall configuration. If you want to distribute this\n",
            "        package, please make sure that 'exllamav2.vlm.processor' is explicitly added\n",
            "        to the `packages` configuration field.\n",
            "\n",
            "        Alternatively, you can also rely on setuptools' discovery methods\n",
            "        (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
            "        instead of `find_packages(...)`/`find:`).\n",
            "\n",
            "        You can read more about \"package discovery\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
            "\n",
            "        If you don't want 'exllamav2.vlm.processor' to be distributed and are\n",
            "        already explicitly excluding 'exllamav2.vlm.processor' via\n",
            "        `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
            "        you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
            "        combination with a more fine grained `package-data` configuration.\n",
            "\n",
            "        You can read more about \"package data files\" on setuptools documentation page:\n",
            "\n",
            "        - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
            "\n",
            "\n",
            "        [^1]: For Python, any directory (with suitable naming) can be imported,\n",
            "              even if it does not contain any `.py` files.\n",
            "              On the other hand, currently there is no concept of package data\n",
            "              directory, all directories are treated like packages.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  check.warn(importable)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:448: UserWarning: The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.4). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:458: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.5\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n",
            "Emitting ninja build file /content/exllamav2/build/temp.linux-x86_64-cpython-311/build.ninja...\n",
            "Compiling objects...\n",
            "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
            "[1/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cpp/profiling.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cpp/profiling.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cpp/profiling.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "[2/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cpp/sampling.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cpp/sampling.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp:274: warning: ignoring ‘#pragma unroll ’ [-Wunknown-pragmas]\n",
            "  274 |     #pragma unroll(32)\n",
            "      | \n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp:277: warning: ignoring ‘#pragma unroll ’ [-Wunknown-pragmas]\n",
            "  277 |     #pragma unroll(32)\n",
            "      | \n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp: In function ‘void apply_rep_penalty_cpu(int, const uint64_t*, float, int, int, float, float, int, float*)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp:78:15: warning: comparison of integer expressions of different signedness: ‘uint64_t’ {aka ‘long unsigned int’} and ‘const int’ [-Wsign-compare]\n",
            "   78 |         if (t < vocab_size)\n",
            "      |             ~~^~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp: In function ‘int xtc_cpu(int, float*, int*, bool*, float, float)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp:824:9: warning: unused variable ‘index’ [-Wunused-variable]\n",
            "  824 |     int index = 0;\n",
            "      |         ^~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp:828:9: warning: variable ‘min_index’ set but not used [-Wunused-but-set-variable]\n",
            "  828 |     int min_index = -1;\n",
            "      |         ^~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp: In function ‘int _Z19softmax_cpu_nonavx2ifPKfPKbfPf.avx2.0(int, float, const float*, const bool*, float, float*)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp:162:12: warning: ‘maxi’ may be used uninitialized in this function [-Wmaybe-uninitialized]\n",
            "  162 |     return maxi;\n",
            "      |            ^~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp: In function ‘int softmax_cpu_nonavx2(int, float, const float*, const bool*, float, float*)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling.cpp:162:12: warning: ‘maxi’ may be used uninitialized in this function [-Wmaybe-uninitialized]\n",
            "  162 |     return maxi;\n",
            "      |            ^~~~\n",
            "[3/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cpp/sampling_avx2.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling_avx2.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cpp/sampling_avx2.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In file included from /content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling_avx2.cpp:15:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/avx_mathfun.h: In function ‘__m256 exp256_ps(__m256)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/avx_mathfun.h:389:10: warning: unused variable ‘exp_hi’ [-Wunused-variable]\n",
            "  389 | __m256   exp_hi        = _mm256_set1_ps(88.3762626647949f);\n",
            "      |          ^~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling_avx2.cpp: In function ‘int softmax_cpu_avx2(int, float, const float*, const bool*, float, float*)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cpp/sampling_avx2.cpp:145:12: warning: ‘maxi’ may be used uninitialized in this function [-Wmaybe-uninitialized]\n",
            "  145 |     return maxi;\n",
            "      |            ^~~~\n",
            "[4/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cpp/generator.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cpp/generator.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cpp/generator.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "[5/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/cache.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/cache.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/cache.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[6/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/kernel_select.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/comp_units/kernel_select.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/kernel_select.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[7/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cpp/quantize_func.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cpp/quantize_func.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cpp/quantize_func.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "[8/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_1a.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_1a.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_1a.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[9/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_2a.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_2a.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_2a.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[10/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_1b.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_1b.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_1b.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[11/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_3a.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_3a.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_3a.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[12/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_gptq_1.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/comp_units/unit_gptq_1.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_gptq_1.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[13/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_2b.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_2b.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_2b.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[14/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_gptq_2.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/comp_units/unit_gptq_2.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_gptq_2.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[15/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_gptq_3.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/comp_units/unit_gptq_3.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_gptq_3.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[16/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/graph.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/graph.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/graph.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cuda/graph.cu: In member function ‘void Graph::inspect_graph()’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cuda/graph.cu:69:8: warning: format ‘%i’ expects argument of type ‘int’, but argument 3 has type ‘std::vector<CUgraphNode_st*>::size_type’ {aka ‘long unsigned int’} [-Wformat=]\n",
            "   69 |     DBGI(nodes.size());\n",
            "      |        ^~~~~~~~~~                              \n",
            "      |                                              |\n",
            "      |                                              std::vector<CUgraphNode_st*>::size_type {aka long unsigned int}\n",
            "[17/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/h_add.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/h_add.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/h_add.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[18/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/h_gemm.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/h_gemm.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/h_gemm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[19/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/head_norm.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/head_norm.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/head_norm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/cuda/head_norm.cu(31): warning #177-D: variable \"x_ptr2\" was declared but never referenced\n",
            "      const half2* x_ptr2 = (const half2*) x_ptr;\n",
            "                   ^\n",
            "\n",
            "Remark: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "[20/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/layer_norm.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/layer_norm.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/layer_norm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[21/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/lora.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/lora.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/lora.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[22/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/pack_tensor.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/pack_tensor.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/pack_tensor.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[23/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_3b.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_3b.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/comp_units/unit_exl2_3b.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[24/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/q_attn.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/q_attn.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/q_attn.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[25/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/q_gemm.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/q_gemm.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/q_gemm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[26/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/q_matrix.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/q_matrix.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/q_matrix.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[27/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/q_mlp.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/q_mlp.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/q_mlp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[28/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/quantize.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/quantize.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/quantize.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[29/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/rms_norm.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/rms_norm.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/rms_norm.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[30/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/rope.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/rope.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/rope.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[31/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/softcap.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/softcap.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/softcap.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[32/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/tp.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/tp.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/tp.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[33/47] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/util.o.d -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/cuda/util.cu -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/cuda/util.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options ''\"'\"'-fPIC'\"'\"'' -lineinfo -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_75,code=compute_75 -gencode=arch=compute_75,code=sm_75 -std=c++17\n",
            "[34/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_cache.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_cache.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_cache.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "[35/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_element.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_element.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_element.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "[36/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_bindings.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_bindings.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_bindings.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "[37/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_gemm.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_gemm.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_gemm.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "[38/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_hadamard.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_hadamard.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_hadamard.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "[39/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_norm.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_norm.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_norm.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_norm.cpp: In function ‘void rms_norm_tp(std::vector<at::Tensor>, std::vector<at::Tensor>, std::vector<at::Tensor>, float, uintptr_t)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_norm.cpp:73:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "   73 |     for (int i = 0; i < x.size(); ++i)\n",
            "      |                     ~~^~~~~~~~~~\n",
            "[40/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_qattn.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_qattn.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_qattn.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qattn.cpp: In lambda function:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qattn.cpp:324:27: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  324 |         for (int i = 0; i < pre_layernorm.size(); ++i)\n",
            "      |                         ~~^~~~~~~~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qattn.cpp:355:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  355 |             for (int i = 0; i < temp_q.size(); ++i)\n",
            "      |                             ~~^~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qattn.cpp:387:27: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  387 |         for (int i = 0; i < temp_q.size(); ++i)\n",
            "      |                         ~~^~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qattn.cpp:453:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  453 |             for (int i = 0; i < temp_bc0.size(); ++i)\n",
            "      |                             ~~^~~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qattn.cpp: In lambda function:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qattn.cpp:560:27: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  560 |         for (int i = 0; i < pre_layernorm.size(); ++i)\n",
            "      |                         ~~^~~~~~~~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qattn.cpp:591:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  591 |             for (int i = 0; i < temp_q.size(); ++i)\n",
            "      |                             ~~^~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qattn.cpp:623:27: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  623 |         for (int i = 0; i < temp_q.size(); ++i)\n",
            "      |                         ~~^~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qattn.cpp:689:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  689 |             for (int i = 0; i < temp_bc0.size(); ++i)\n",
            "      |                             ~~^~~~~~~~~~~~~~~~~\n",
            "[41/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_qmatrix.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_qmatrix.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_qmatrix.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "In file included from /usr/local/lib/python3.11/dist-packages/torch/include/c10/util/Exception.h:5,\n",
            "                 from /usr/local/lib/python3.11/dist-packages/torch/include/c10/core/Device.h:5,\n",
            "                 from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/TensorBody.h:11,\n",
            "                 from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/core/Tensor.h:3,\n",
            "                 from /usr/local/lib/python3.11/dist-packages/torch/include/ATen/Tensor.h:3,\n",
            "                 from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/function_hook.h:3,\n",
            "                 from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/cpp_hook.h:2,\n",
            "                 from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/variable.h:6,\n",
            "                 from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/autograd/autograd.h:3,\n",
            "                 from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/autograd.h:3,\n",
            "                 from /usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:7,\n",
            "                 from /usr/local/lib/python3.11/dist-packages/torch/include/torch/extension.h:5,\n",
            "                 from /content/exllamav2/exllamav2/exllamav2_ext/ext_qmatrix.cpp:1:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qmatrix.cpp: In function ‘uintptr_t make_q_matrix(at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, at::Tensor, int)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qmatrix.cpp:80:37: warning: comparison of integer expressions of different signedness: ‘int64_t’ {aka ‘long int’} and ‘uint64_t’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "   80 |         TORCH_CHECK(temp_dq.size(0) >= dq_req, \"Insufficient size of temp_dq buffer\")\n",
            "      |                     ~~~~~~~~~~~~~~~~^~~~~~~~~\n",
            "/usr/local/lib/python3.11/dist-packages/torch/include/c10/macros/Macros.h:193:64: note: in definition of macro ‘C10_UNLIKELY’\n",
            "  193 | #define C10_UNLIKELY(expr) (__builtin_expect(static_cast<bool>(expr), 0))\n",
            "      |                                                                ^~~~\n",
            "/usr/local/lib/python3.11/dist-packages/torch/include/c10/util/Exception.h:575:7: note: in expansion of macro ‘C10_UNLIKELY_OR_CONST’\n",
            "  575 |   if (C10_UNLIKELY_OR_CONST(!(cond))) {            \\\n",
            "      |       ^~~~~~~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qmatrix.cpp:80:9: note: in expansion of macro ‘TORCH_CHECK’\n",
            "   80 |         TORCH_CHECK(temp_dq.size(0) >= dq_req, \"Insufficient size of temp_dq buffer\")\n",
            "      |         ^~~~~~~~~~~\n",
            "[42/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_qmlp.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_qmlp.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_qmlp.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qmlp.cpp: In lambda function:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qmlp.cpp:374:27: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  374 |         for (int i = 0; i < pre_layernorm.size(); ++i)\n",
            "      |                         ~~^~~~~~~~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qmlp.cpp:402:27: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  402 |         for (int i = 0; i < temp_bc1.size(); ++i)\n",
            "      |                         ~~^~~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qmlp.cpp:434:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<at::Tensor>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  434 |             for (int i = 0; i < temp_bc0.size(); ++i)\n",
            "      |                             ~~^~~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qmlp.cpp: In function ‘void tp_mlp_forward_(uintptr_t, at::Tensor, const std::vector<at::Tensor>&, const std::vector<at::Tensor>&, const std::vector<at::Tensor>&, const std::vector<at::Tensor>&, const std::vector<at::Tensor>&, const std::vector<at::Tensor>&, const std::vector<at::Tensor>&, float, const std::vector<long unsigned int>&, const std::vector<long unsigned int>&, const std::vector<long unsigned int>&, bool)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_qmlp.cpp:346:9: warning: unused variable ‘interm_dim’ [-Wunused-variable]\n",
            "  346 |     int interm_dim = temp_bc2_[0].size(1);\n",
            "      |         ^~~~~~~~~~\n",
            "[43/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_quant.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_quant.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_quant.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "[44/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_rope.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_rope.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_rope.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_rope.cpp: In function ‘int64_t gen_mrope_pos_ids(at::Tensor, at::Tensor, int, const std::vector<std::tuple<long int, long int> >&, const std::vector<std::tuple<long int, long int, long int> >&)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_rope.cpp:90:31: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<std::tuple<long int, long int> >::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "   90 |             for (int j = 0; j < spans.size(); ++j)\n",
            "      |                             ~~^~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_rope.cpp:94:25: warning: unused variable ‘span’ [-Wunused-variable]\n",
            "   94 |                 int64_t span = span_end - span_start;\n",
            "      |                         ^~~~\n",
            "[45/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_sampling.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_sampling.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_sampling.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_sampling.cpp: In instantiation of ‘fast_copy_cpu(at::Tensor, at::Tensor)::<lambda(auto:29&, int64_t, int64_t, int)> [with auto:29 = fast_copy_cpu(at::Tensor, at::Tensor)::<lambda(auto:29&, int64_t, int64_t, int)>; int64_t = long int]’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_sampling.cpp:419:23:   required from here\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_sampling.cpp:403:21: warning: comparison of integer expressions of different signedness: ‘int’ and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  403 |             if (dim == sizes.size())\n",
            "      |                 ~~~~^~~~~~~~~~~~~~~\n",
            "[46/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_stloader.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_stloader.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_stloader.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_stloader.cpp: In lambda function:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_stloader.cpp:64:24: warning: comparison of integer expressions of different signedness: ‘ssize_t’ {aka ‘long int’} and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "   64 |                 if (br != pos_b - pos_a) goto error;\n",
            "      |                     ~~~^~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_stloader.cpp:65:21: warning: unused variable ‘sr’ [-Wunused-variable]\n",
            "   65 |                 int sr = fseek(file, offset + pos_a, SEEK_SET);\n",
            "      |                     ^~\n",
            "[47/47] c++ -MMD -MF /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_tp.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp -o /content/exllamav2/build/temp.linux-x86_64-cpython-311/exllamav2/exllamav2_ext/ext_tp.o -O3 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=exllamav2_ext -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp: In constructor ‘ExtTPContext::ExtTPContext(std::vector<std::tuple<int, int, int> >, std::vector<std::tuple<int, int, int> >, std::vector<std::tuple<int, int, int> >, std::vector<std::tuple<int, int, int> >, std::vector<std::tuple<int, int, int> >, std::vector<at::Tensor>, std::vector<CUstream_st*>)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:49:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<CUstream_st*>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "   49 |     for (int i = 0; i < streams.size(); ++i)\n",
            "      |                     ~~^~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:54:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<CUstream_st*>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "   54 |     for (int i = 0; i < streams.size(); ++i)\n",
            "      |                     ~~^~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp: In function ‘uintptr_t make_tp_context(std::vector<std::tuple<int, int, int> >, std::vector<std::tuple<int, int, int> >, std::vector<std::tuple<int, int, int> >, std::vector<std::tuple<int, int, int> >, std::vector<std::tuple<int, int, int> >, std::vector<at::Tensor>, std::vector<long unsigned int>)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:103:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<long unsigned int>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  103 |     for (int i = 0; i < streams.size(); ++i)\n",
            "      |                     ~~^~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp: In function ‘void tp_broadcast(uintptr_t, int, at::Tensor, int, const std::vector<at::Tensor>&, int, int)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:168:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<std::tuple<int, int, int> >::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  168 |     for (int i = 0; i < split.size(); ++i)\n",
            "      |                     ~~^~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp: In function ‘void tp_gather_barrier(uintptr_t, int, const std::vector<at::Tensor>&, int, const std::vector<at::Tensor>&, int, int, int, Barrier*)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:239:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<std::tuple<int, int, int> >::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  239 |     for (int i = 0; i < split.size(); ++i)\n",
            "      |                     ~~^~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:282:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<std::tuple<int, int, int> >::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  282 |     for (int i = 0; i < split.size(); ++i)\n",
            "      |                     ~~^~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp: In function ‘void tp_cross_device_barrier(uintptr_t, int, int, int, int)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:348:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<int>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  348 |     for (int i = 0; i < ctx->all_devices.size(); ++i)\n",
            "      |                     ~~^~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:355:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<int>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  355 |     for (int i = 0; i < ctx->all_devices.size(); ++i)\n",
            "      |                     ~~^~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:357:27: warning: comparison of integer expressions of different signedness: ‘int’ and ‘std::vector<int>::size_type’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  357 |         for (int j = 0; j < ctx->all_devices.size(); ++j)\n",
            "      |                         ~~^~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:323:15: warning: unused variable ‘sync’ [-Wunused-variable]\n",
            "  323 |     uint32_t* sync = ctx->tp_data->sync[stage];\n",
            "      |               ^~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:324:15: warning: unused variable ‘sync_next’ [-Wunused-variable]\n",
            "  324 |     uint32_t* sync_next = ctx->tp_data->sync[next_stage];\n",
            "      |               ^~~~~~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp: In function ‘void tp_all_reduce(uintptr_t, int, const std::vector<at::Tensor>&, const std::vector<at::Tensor>&)’:\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:419:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  419 |     for (int i = 0; i < num; ++i)\n",
            "      |                     ~~^~~~~\n",
            "/content/exllamav2/exllamav2/exllamav2_ext/ext_tp.cpp:475:23: warning: comparison of integer expressions of different signedness: ‘int’ and ‘size_t’ {aka ‘long unsigned int’} [-Wsign-compare]\n",
            "  475 |     for (int i = 0; i < num - 1; ++i)\n",
            "      |                     ~~^~~~~~~~~\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.exllamav2_ext.cpython-311: module references __file__\n",
            "exllamav2.__pycache__.ext.cpython-311: module references __file__\n",
            "exllamav2.conversion.__pycache__.tokenize.cpython-311: module references __file__\n",
            "exllamav2.hadamard.__pycache__.hadamard.cpython-311: module references __file__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Method = \"EXL2\" # @param [\"EXL2\", \"GptQ\"] {allow-input: true}\n",
        "Model = \"turboderp/Llama-3.2-1B-exl2\" #@param [\"\"]{allow-input: true}\n",
        "bpw = \"2.5bpw\" # @param [\"2.5bpw\", \"4.0bpw\", \"8.0bpw\"] {allow-input: true}\n",
        "!pip install -U huggingface-hub\n",
        "!mkdir models\n",
        "if Method:=\"EXL2\":\n",
        "  !cd models && huggingface-cli download $Model --revision {bpw} --local-dir /content/models --local-dir-use-symlinks False\n",
        "else:\n",
        "  !cd models && huggingface-cli download $Model --local-dir /content/models --local-dir-use-symlinks False\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sAPRd2Ikyv1",
        "outputId": "f385a8aa-fae2-45e2-b219-c3fc79318d9a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mDEPRECATION: Loading egg at /root/.local/lib/python3.11/site-packages/exllamav2-0.2.8-py3.11-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages/setuptools/_vendor (from huggingface-hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages/setuptools/_vendor (from huggingface-hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub) (2025.1.31)\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/commands/download.py:139: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
            "  warnings.warn(\n",
            "Fetching 10 files:   0% 0/10 [00:00<?, ?it/s]Downloading 'USE_POLICY.md' to '/content/models/.cache/huggingface/download/UcPfAI5B08awK9_TiALuc0iOThI=.ac3c5f21b9779e3da0677d6d3c587778fe3a331e.incomplete'\n",
            "Downloading 'special_tokens_map.json' to '/content/models/.cache/huggingface/download/ahkChHUJFxEmOdq5GDFEmerRzCY=.cfabacc2620186cd3dd4b1dde9a37e057208636e.incomplete'\n",
            "Downloading 'README.md' to '/content/models/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.6e6edfe1d488f4eeb14da7a3eec70d242e5779e0.incomplete'\n",
            "Downloading 'generation_config.json' to '/content/models/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.2d73a6863086ff9d491c28e49df9fb697cd92c2b.incomplete'\n",
            "\n",
            "USE_POLICY.md: 100% 6.02k/6.02k [00:00<00:00, 24.8MB/s]\n",
            "Download complete. Moving file to /content/models/USE_POLICY.md\n",
            "\n",
            "special_tokens_map.json: 100% 301/301 [00:00<00:00, 1.93MB/s]\n",
            "Download complete. Moving file to /content/models/special_tokens_map.json\n",
            "Downloading 'LICENSE.txt' to '/content/models/.cache/huggingface/download/cyBuwAu93UXke23CJCWORBYR70A=.085b47c1575cb889b7024030e60b78f54f0b8c9e.incomplete'\n",
            "Downloading 'config.json' to '/content/models/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.dc221ca1b54f7e8c1773395f0126df5b7b0c4ecf.incomplete'\n",
            "\n",
            "README.md: 100% 35.4k/35.4k [00:00<00:00, 3.72MB/s]\n",
            "Download complete. Moving file to /content/models/README.md\n",
            "Downloading 'output.safetensors' to '/content/models/.cache/huggingface/download/2regD2SwVb9sZxeoA_WsW5_KDvM=.17fd12af077ca6870ab70135f360f137c61a6f34259aafa9abc851e4dd0a10de.incomplete'\n",
            "\n",
            "generation_config.json: 100% 185/185 [00:00<00:00, 1.21MB/s]\n",
            "Download complete. Moving file to /content/models/generation_config.json\n",
            "Downloading 'tokenizer.json' to '/content/models/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.5cc5f00a5b203e90a27a3bd60d1ec393b07971e8.incomplete'\n",
            "Downloading 'tokenizer_config.json' to '/content/models/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.cb9ec25536e44d86778b10509d3e5bdca459a5cf.incomplete'\n",
            "\n",
            "config.json: 100% 1.18k/1.18k [00:00<00:00, 8.58MB/s]\n",
            "Download complete. Moving file to /content/models/config.json\n",
            "\n",
            "LICENSE.txt: 100% 7.71k/7.71k [00:00<00:00, 33.5MB/s]\n",
            "Download complete. Moving file to /content/models/LICENSE.txt\n",
            "Downloading '.gitattributes' to '/content/models/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.a6344aac8c09253b3b630fb776ae94478aa0275b.incomplete'\n",
            "\n",
            "tokenizer.json:   0% 0.00/9.09M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "tokenizer_config.json: 100% 50.5k/50.5k [00:00<00:00, 15.7MB/s]\n",
            "Download complete. Moving file to /content/models/tokenizer_config.json\n",
            "\n",
            "\n",
            ".gitattributes: 100% 1.52k/1.52k [00:00<00:00, 5.89MB/s]\n",
            "Download complete. Moving file to /content/models/.gitattributes\n",
            "Fetching 10 files:  10% 1/10 [00:00<00:05,  1.62it/s]\n",
            "\n",
            "output.safetensors:   0% 0.00/1.04G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:   1% 10.5M/1.04G [00:00<00:18, 55.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:   2% 21.0M/1.04G [00:00<00:18, 54.8MB/s]\u001b[A\u001b[A\n",
            "tokenizer.json: 100% 9.09M/9.09M [00:00<00:00, 12.1MB/s]\n",
            "Download complete. Moving file to /content/models/tokenizer.json\n",
            "\n",
            "\n",
            "output.safetensors:   3% 31.5M/1.04G [00:00<00:17, 56.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:   4% 41.9M/1.04G [00:00<00:17, 57.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:   5% 52.4M/1.04G [00:00<00:17, 57.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:   6% 62.9M/1.04G [00:01<00:17, 57.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:   7% 73.4M/1.04G [00:01<00:16, 57.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:   8% 83.9M/1.04G [00:01<00:16, 57.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:   9% 94.4M/1.04G [00:01<00:16, 57.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  10% 105M/1.04G [00:01<00:16, 57.5MB/s] \u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  11% 115M/1.04G [00:02<00:16, 57.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  12% 126M/1.04G [00:02<00:15, 57.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  13% 136M/1.04G [00:02<00:15, 57.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  14% 147M/1.04G [00:02<00:15, 57.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  15% 157M/1.04G [00:02<00:15, 57.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  16% 168M/1.04G [00:02<00:15, 57.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  17% 178M/1.04G [00:03<00:15, 57.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  18% 189M/1.04G [00:03<00:14, 57.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  19% 199M/1.04G [00:03<00:14, 57.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  20% 210M/1.04G [00:03<00:14, 56.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  21% 220M/1.04G [00:03<00:15, 53.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  22% 231M/1.04G [00:04<00:20, 38.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  23% 241M/1.04G [00:04<00:18, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  24% 252M/1.04G [00:04<00:17, 46.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  25% 262M/1.04G [00:04<00:15, 48.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  26% 273M/1.04G [00:05<00:17, 45.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  27% 283M/1.04G [00:05<00:15, 48.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  28% 294M/1.04G [00:05<00:14, 50.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  29% 304M/1.04G [00:05<00:15, 48.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  30% 315M/1.04G [00:05<00:14, 50.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  31% 325M/1.04G [00:06<00:13, 52.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  32% 336M/1.04G [00:06<00:13, 53.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  33% 346M/1.04G [00:06<00:14, 49.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  34% 357M/1.04G [00:06<00:13, 51.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  35% 367M/1.04G [00:06<00:12, 52.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  36% 377M/1.04G [00:07<00:12, 54.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  37% 388M/1.04G [00:07<00:11, 55.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  38% 398M/1.04G [00:07<00:11, 55.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  39% 409M/1.04G [00:07<00:11, 56.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  40% 419M/1.04G [00:07<00:11, 56.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  41% 430M/1.04G [00:08<00:10, 56.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  42% 440M/1.04G [00:08<00:10, 57.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  43% 451M/1.04G [00:08<00:10, 57.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  44% 461M/1.04G [00:08<00:10, 57.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  45% 472M/1.04G [00:08<00:09, 57.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  46% 482M/1.04G [00:08<00:09, 57.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  47% 493M/1.04G [00:09<00:09, 57.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  48% 503M/1.04G [00:09<00:10, 53.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  49% 514M/1.04G [00:09<00:09, 54.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  50% 524M/1.04G [00:09<00:09, 55.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  51% 535M/1.04G [00:10<00:11, 44.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  52% 545M/1.04G [00:10<00:11, 44.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  53% 556M/1.04G [00:10<00:10, 47.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  54% 566M/1.04G [00:10<00:09, 50.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  55% 577M/1.04G [00:10<00:10, 45.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  56% 587M/1.04G [00:11<00:09, 48.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  57% 598M/1.04G [00:11<00:08, 51.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  58% 608M/1.04G [00:11<00:08, 51.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  59% 619M/1.04G [00:11<00:07, 54.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  60% 629M/1.04G [00:11<00:08, 49.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  62% 640M/1.04G [00:12<00:07, 51.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  63% 650M/1.04G [00:12<00:07, 52.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  64% 661M/1.04G [00:12<00:07, 53.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  65% 671M/1.04G [00:12<00:07, 49.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  66% 682M/1.04G [00:12<00:06, 51.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  67% 692M/1.04G [00:13<00:06, 53.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  68% 703M/1.04G [00:13<00:06, 54.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  69% 713M/1.04G [00:13<00:05, 54.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  70% 724M/1.04G [00:13<00:05, 55.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  71% 734M/1.04G [00:13<00:05, 55.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  72% 744M/1.04G [00:14<00:06, 44.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  73% 755M/1.04G [00:14<00:07, 39.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  74% 765M/1.04G [00:14<00:06, 43.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  75% 776M/1.04G [00:14<00:05, 47.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  76% 786M/1.04G [00:15<00:05, 49.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  77% 797M/1.04G [00:15<00:04, 51.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  78% 807M/1.04G [00:15<00:04, 50.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  79% 818M/1.04G [00:15<00:04, 52.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  80% 828M/1.04G [00:15<00:03, 53.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  81% 839M/1.04G [00:16<00:03, 54.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  82% 849M/1.04G [00:16<00:03, 55.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  83% 860M/1.04G [00:16<00:03, 56.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  84% 870M/1.04G [00:16<00:03, 50.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  85% 881M/1.04G [00:16<00:02, 59.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  86% 891M/1.04G [00:16<00:02, 58.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  87% 902M/1.04G [00:17<00:02, 56.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  88% 912M/1.04G [00:17<00:02, 56.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  89% 923M/1.04G [00:17<00:02, 56.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  90% 933M/1.04G [00:17<00:02, 45.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  91% 944M/1.04G [00:18<00:01, 48.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  92% 954M/1.04G [00:18<00:01, 50.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  93% 965M/1.04G [00:18<00:01, 52.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  94% 975M/1.04G [00:18<00:01, 53.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  95% 986M/1.04G [00:18<00:01, 52.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  96% 996M/1.04G [00:19<00:00, 53.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  97% 1.01G/1.04G [00:19<00:00, 55.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  98% 1.02G/1.04G [00:19<00:00, 53.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors:  99% 1.03G/1.04G [00:19<00:00, 50.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "output.safetensors: 100% 1.04G/1.04G [00:19<00:00, 52.3MB/s]\n",
            "Download complete. Moving file to /content/models/output.safetensors\n",
            "Fetching 10 files: 100% 10/10 [00:20<00:00,  2.06s/it]\n",
            "/content/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!wget -c https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "!nohup ./cloudflared-linux-amd64 tunnel --url http://localhost:5000 &\n",
        "!sleep 5\n",
        "!cat nohup.out\n",
        "!cd exui && python server.py --host 127.0.0.1:5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzA0TGN0lDcU",
        "outputId": "18ca8bab-1434-4a69-b579-4afc865b0529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-25 23:33:15--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.2.1/cloudflared-linux-amd64 [following]\n",
            "--2025-03-25 23:33:16--  https://github.com/cloudflare/cloudflared/releases/download/2025.2.1/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/eac8237f-c554-46b5-95ea-f2f5873e69a5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250325%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250325T233316Z&X-Amz-Expires=300&X-Amz-Signature=15c8a89ca4ce6ca0c3493db6080a0c7ad2c58d3f5ba6440cc81df25a852bf225&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-25 23:33:16--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/eac8237f-c554-46b5-95ea-f2f5873e69a5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250325%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250325T233316Z&X-Amz-Expires=300&X-Amz-Signature=15c8a89ca4ce6ca0c3493db6080a0c7ad2c58d3f5ba6440cc81df25a852bf225&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37844205 (36M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  36.09M   215MB/s    in 0.2s    \n",
            "\n",
            "2025-03-25 23:33:16 (215 MB/s) - ‘cloudflared-linux-amd64’ saved [37844205/37844205]\n",
            "\n",
            "nohup: appending output to 'nohup.out'\n",
            "2025-03-25T23:33:17Z INF Thank you for trying Cloudflare Tunnel. Doing so, without a Cloudflare account, is a quick way to experiment and try it out. However, be aware that these account-less Tunnels have no uptime guarantee, are subject to the Cloudflare Online Services Terms of Use (https://www.cloudflare.com/website-terms/), and Cloudflare reserves the right to investigate your use of Tunnels for violations of such terms. If you intend to use Tunnels in production you should use a pre-created named tunnel by following: https://developers.cloudflare.com/cloudflare-one/connections/connect-apps\n",
            "2025-03-25T23:33:17Z INF Requesting new quick Tunnel on trycloudflare.com...\n",
            "2025-03-25T23:33:22Z INF +--------------------------------------------------------------------------------------------+\n",
            "2025-03-25T23:33:22Z INF |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n",
            "2025-03-25T23:33:22Z INF |  https://fifth-tropical-iraqi-processing.trycloudflare.com                                 |\n",
            "2025-03-25T23:33:22Z INF +--------------------------------------------------------------------------------------------+\n",
            " -- User dir: ~/exui\n",
            " -- Starting server on 127.0.0.1 port 5000\n",
            "Found generation_config.json: {'_from_model_config': True, 'bos_token_id': 128000, 'eos_token_id': 128001, 'transformers_version': '4.45.0.dev0', 'do_sample': True, 'temperature': 0.6, 'top_p': 0.9}\n",
            "Setting temperature from None to 0.6\n",
            "Setting top_p from None to 0.9\n",
            "Final model parameters: {'temperature': 0.6, 'top_k': 50, 'top_p': 0.9, 'repp': 1.01}\n",
            "Loading model: /content/models\n",
            "Calling model_loaded_callback with params: {'temperature': 0.6, 'top_k': 50, 'top_p': 0.9, 'repp': 1.01}\n"
          ]
        }
      ]
    }
  ]
}